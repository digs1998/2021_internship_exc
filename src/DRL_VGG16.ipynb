{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRL VGG16",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6etAqXpHmqQ"
      },
      "source": [
        "##Cloning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifXy0XmNHc4W",
        "outputId": "8b9e1f2f-5bea-4bda-b2ab-141adcc8dd17"
      },
      "source": [
        "!git clone https://github.com/digs1998/2021_internship_exc.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '2021_internship_exc'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 146 (delta 11), reused 112 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 737.99 KiB | 16.77 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH9i5WE4JM7y"
      },
      "source": [
        "##Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACIbn2TWIB88"
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import spatial\n",
        "import random\n",
        "import ssl\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import pickle \n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IXOxGqyfJ0KT",
        "outputId": "e37899b3-ac5e-4c1d-a6b4-275c015ad713"
      },
      "source": [
        "##testing GPU\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCRm8_U0KZdA"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "      img = load_img(os.path.join(folder,filename),  target_size=(224, 224))\n",
        "      img = img_to_array(img)\n",
        "      img = img.reshape((1,) + img.shape)\n",
        "      if img is not None:\n",
        "        images.append(img)\n",
        "    return images"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft_S7J_zMemK"
      },
      "source": [
        "def get_all_image_arrays():\n",
        "  image1 = load_images_from_folder('/content/2021_internship_exc/data/color')\n",
        "  image2 = load_images_from_folder('/content/2021_internship_exc/data/grayscale')\n",
        "\n",
        "  all_arrays = np.array([image1+image2])\n",
        "  return all_arrays"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEBaOO6jUCN0"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTAuhQSWM4Y8"
      },
      "source": [
        "# # consine similarity\n",
        "# def cosine_similarity(ratings):\n",
        "#     sim = ratings.dot(ratings.T)\n",
        "#     norms = np.array([np.sqrt(np.diagonal(sim))])\n",
        "#     return (sim / norms / norms.T)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuk5ES8gUJlM"
      },
      "source": [
        "## Creating Datasets from Color Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuHCnM2BPJa5"
      },
      "source": [
        "files = os.listdir(\"/content/2021_internship_exc/data/color\")\n",
        "ytest = []\n",
        "xtest = []\n",
        "for file in files:\n",
        "  abs_file_path = '/content/2021_internship_exc/data/color/' + file\n",
        "  img = image.load_img(abs_file_path, target_size=(224, 224))\n",
        "  ytest.append((file[0:2]))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  if len(xtest) > 0:\n",
        "    xtest = np.concatenate((xtest, x))\n",
        "  else:\n",
        "    xtest = x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtgGfPibR5HI",
        "outputId": "f2729ff1-bb70-4a8b-cb34-c436a6a5e352"
      },
      "source": [
        "xtest.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxxz0mp0MBTd"
      },
      "source": [
        "##Creating Model VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vwyKpoqLXMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2fa94a-e62b-4dec-e9b4-139285f4e784"
      },
      "source": [
        "# convert input to VGG format\n",
        "xtest = preprocess_input(xtest)\n",
        "\n",
        "# include_top=False: exclude top(last) 3 fully-connected layers. get features dim=(1,7,7,512)\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# use VGG to extract features\n",
        "features = model.predict(xtest)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfjJBZe-SO_y"
      },
      "source": [
        "# flatten as one dimension\n",
        "features_compress = features.reshape(len(ytest), 7 * 7 * 512)\n",
        "\n",
        "# compute consine similarity\n",
        "cos_sim = cosine_similarity(features_compress)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8oX2MN7TAtB",
        "outputId": "47213cfa-8a36-44a2-a702-915e78d85556"
      },
      "source": [
        "print(cos_sim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.54535335 0.6393365  ... 0.83716935 0.889364   0.54535335]\n",
            " [0.54535335 1.         0.50482345 ... 0.51372063 0.5261925  1.        ]\n",
            " [0.6393365  0.50482345 1.0000001  ... 0.62474465 0.6186621  0.50482345]\n",
            " ...\n",
            " [0.83716935 0.51372063 0.62474465 ... 1.         0.8998418  0.51372063]\n",
            " [0.889364   0.5261925  0.6186621  ... 0.8998418  1.0000002  0.5261925 ]\n",
            " [0.54535335 1.         0.50482345 ... 0.51372063 0.5261925  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPdKKL1wWvWY"
      },
      "source": [
        "##saving as npz file\n",
        "with open('vgg16_similarity.npz', 'wb') as pickle_file:\n",
        "    pickle.dump(cos_sim, pickle_file)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyUHbhb9fxas"
      },
      "source": [
        "## Summary\n",
        "- I have implemented vgg-16 based cosine similarity model.\n",
        "- I didn't use the suggested input parameters, as I wasn't sure on how to proceed with them.\n",
        "- with respect to the output generation, I have created a .npz file"
      ]
    }
  ]
}